{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_mod(df, logProb = 1.0):\n",
    "    from sklearn import linear_model\n",
    "\n",
    "    ## Prepare data for model\n",
    "    nrow = df.shape[0]\n",
    "    X = df[['x', 'y']].as_matrix().reshape(nrow,2)\n",
    "    Y = df.z.as_matrix().ravel() #reshape(nrow,1)\n",
    "    ## Compute the logistic regression model\n",
    "    lg = linear_model.LogisticRegression()\n",
    "    logr = lg.fit(X, Y)\n",
    "    ## Compute the y values\n",
    "    temp = logr.predict_log_proba(X)  \n",
    "    df['predicted']  = [1 if (logProb > p[1]/p[0]) else 0 for p in temp]\n",
    "    return df\n",
    "\n",
    "def eval_logistic(df):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "\n",
    "    truePos = df[((df['predicted'] == 1) & (df['z'] == df['predicted']))]  \n",
    "    falsePos = df[((df['predicted'] == 1) & (df['z'] != df['predicted']))] \n",
    "    trueNeg = df[((df['predicted'] == 0) & (df['z'] == df['predicted']))]  \n",
    "    falseNeg = df[((df['predicted'] == 0) & (df['z'] != df['predicted']))]\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    fig.clf()\n",
    "    ax = fig.gca()\n",
    "    truePos.plot(kind = 'scatter', x = 'x', y = 'y', ax = ax, \n",
    "                       alpha = 1.0, color = 'DarkBlue', marker = '+', s = 80) \n",
    "    falsePos.plot(kind = 'scatter', x = 'x', y = 'y', ax = ax, \n",
    "                       alpha = 1.0, color = 'Red', marker = 'o', s = 40)  \n",
    "    trueNeg.plot(kind = 'scatter', x = 'x', y = 'y', ax = ax, \n",
    "                       alpha = 1.0, color = 'DarkBlue', marker = 'o', s = 40)  \n",
    "    falseNeg.plot(kind = 'scatter', x = 'x', y = 'y', ax = ax, \n",
    "                       alpha = 1.0, color = 'Red', marker = '+', s = 80) \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_title('Classes vs X and Y')\n",
    "    \n",
    "    TP = truePos.shape[0]\n",
    "    FP = falsePos.shape[0]\n",
    "    TN = trueNeg.shape[0]\n",
    "    FN = falseNeg.shape[0]\n",
    "       \n",
    "    confusion = pd.DataFrame({'Positive': [FP, TP],\n",
    "                              'Negative': [TN, FN]},\n",
    "                               index = ['TrueNeg', 'TruePos'])\n",
    "    accuracy = float(TP + TN)/float(TP + TN + FP + FN)      \n",
    "    precision = float(TP)/float(TP + FP)     \n",
    "    recall =  float(TP)/float(TP + FN)      \n",
    "    \n",
    "    print(confusion)\n",
    "    print('accracy = ' + str(accuracy))\n",
    "    print('precision = ' + str(precision))\n",
    "    print('recall = ' + str(recall))\n",
    "    \n",
    "    return 'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## K Nearest Neighbors Classification\n",
    "SKlearn prepartions your data using kd-trees. Prediction based on majority vote; probably best to use an odd number of k-neighbors with binary classification.\n",
    "\n",
    "Choose best fitting distance measure. Be carefull wiht **imbalanced labeled dataset** when choosing you distance measure: in this case using uniform or user-defined weighting may be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data   = [[0],[1],[2],[3],[4], [5],[6],[7],[8],[9]]  # input dataframe samples\n",
    "labels = [0,0,0,0,0, 1,1,1,1,1]  # the function we're training is \" >4 \"\n",
    "data_train, data_test, label_train, label_test = train_test_split(data, labels, test_size=0.5, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(data_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(data_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80000000000000004"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model evaluation\n",
    "model.score(data_test, label_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
