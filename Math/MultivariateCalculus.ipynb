{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Calculus\n",
    "Multivariate of multivariable calculus: subtle difference in the number of input and/or output variables. Not much of a problem in calculus and generally of more concern in the field of statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "This process of selecting a candidate function or hypothesis to model a world is what the great geniuses of science are remembered for. There then follows a potentially long and difficult process of testing this hypothesis but there will be nothing to test without that first creative step. Calculus is simply the study of how these functions change with respect to their input variables and it allows you to investigate and manipulate them.\n",
    "\n",
    "$f(x) = x^{2} + 3$ <br>\n",
    "$f(x) = g(x) + h(x-a)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivative\n",
    "Rise increase vertical direction and run increase horizontal direction. <br>\n",
    "$Gradient = \\frac{rise}{run}$ <br>\n",
    "$\\frac{d \\mathbf{f}}{d \\mathbf{x}} = f'(x) = \\lim_{\\Delta x \\to 0} \\frac{f(x + \\Delta x) - f(x)}{\\Delta x}$ <br> <br>\n",
    "__Sum Rule__<br>\n",
    "$\\frac{d}{d \\mathbf{x}}(f(x)+g(x)) = \\frac{d \\mathbf{f(x)}}{d \\mathbf{x}} + \\frac{d \\mathbf{g(x)}}{d \\mathbf{x}}$<br> <br>\n",
    "__Power Rule__ <br>\n",
    "if $f(x) = ax^b$ then $f'(x) = abx^{b-1}$<br><br>\n",
    "__Special Cases__ <br>\n",
    "$f(x) = \\frac{1}{x}$ then $f'(x) = \\frac{-1}{x^2}$<br>\n",
    "$f(x) = e^x$ then $f'(x) = e^x$ <br>\n",
    "Trigonometric functions are exponential functions in disguise: <br>\n",
    "$f(x) = sin(x)$ then $f'(x) = cos(x)$ <br>\n",
    "$f(x) = cos(x)$ then $f'(x) = -sin(x)$ <br> <br>\n",
    "__Product Rule__<br>\n",
    "$if \\space A(x) = f(x)g(x) \\space then \\space \\lim_{\\Delta x \\to 0} \\frac{\\Delta A(x)}{\\Delta x} = \\lim_{\\Delta x \\to 0} f(x)g'(x) + g(x)f'(x)$ <br> <br>\n",
    "__Chain Rule__ <br>\n",
    "if $h=h(p) \\space and \\space p = p(m)$ \n",
    "then $\\frac{d \\mathbf{h}}{d \\mathbf{m}} = \\frac{d \\mathbf{p}}{d \\mathbf{m}} * \\frac{d \\mathbf{h}}{d \\mathbf{p}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables, constants & context\n",
    "__Partial derivative__<br>\n",
    "Independent variables x and dependent variables y. Examples using partial differentiation treating all other variables as constants.<br>\n",
    "$ m =2\\pi r^2 tp + 2 \\pi rh tp$<br><br>\n",
    "$\\frac{\\partial m}{\\partial h} = 2 \\pi rtp$<br><br>\n",
    "$\\frac{\\partial m}{\\partial r} = 4 \\pi tp + 2 \\pi htp$<br><br>\n",
    "$\\frac{\\partial m}{\\partial t} = 2 \\pi r^2 p + 2 \\pi rhp$<br><br>\n",
    "$\\frac{\\partial m}{\\partial p} = 2 \\pi r^2 t  + 2 \\pi rht$<br><br>\n",
    "__Total derivative__<br>\n",
    "$f(x,y,z) = sin(x)e^{yz^2}$<br>\n",
    "$x = t -1; y = t^2; z = \\frac{1}{t}$<br>\n",
    "$\\frac{d \\mathbf{f(x,y,z)}}{d \\mathbf{t}} = \n",
    "\\frac{\\partial f}{\\partial x} \\frac{d \\mathbf{x}}{d \\mathbf{t}}+ \n",
    "\\frac{\\partial f}{\\partial y} \\frac{d \\mathbf{y}}{d \\mathbf{t}}+ \n",
    "\\frac{\\partial f}{\\partial z} \\frac{d \\mathbf{z}}{d \\mathbf{t}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jacobian\n",
    "We now have an algebraic expression for a vector which when we give it a specific  x, y, z coordinate, will return a vector pointing in the __direction of steepest uphil slope__ of this function. Furthermore, the steeper the slope, the greater the magnitude of Jacobian at that point. The Jacobian describes the gradient of a multivariable system. And if you calculate it for a scalar valued multivariable function, you get a row vector pointing up the direction of greater slope, with a length proportional to the local steepness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if $f(x_1, x_2, x_3, ...)$ then $J=[\\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\frac{\\partial f}{\\partial x_3}]$ (by convention a row vector instead of column vector) <br> <br>\n",
    "\n",
    "if $u(x,y) = x - 2y$ and $v(x,y) = 3y - 2x$ then <br>\n",
    "$J_u = [\\frac{\\partial u}{\\partial x} \\frac{\\partial u}{\\partial y}]$ <br>\n",
    "$J_v = [\\frac{\\partial v}{\\partial x} \\frac{\\partial v}{\\partial y}]$ <br>\n",
    "\n",
    "\n",
    "Building a Jocabian matrix for vectored valued functions. A matrix transformation from xy space to uv space.<br>\n",
    "$J = \n",
    "\\begin{vmatrix}\n",
    "\\frac{\\partial u}{\\partial x} & \\frac{\\partial u}{\\partial y} \\\\\n",
    "\\frac{\\partial v}{\\partial x}  & \\frac{\\partial v}{\\partial y}\n",
    "\\end{vmatrix}$ <br><br>\n",
    "\n",
    "At J(0,0) = [0,0] then this is probably a maximum, minimum or saddle.\n",
    "\n",
    "However in the real world the function will be much more complicated. Thankfully they may often be considered smooth, meaning that when looking at small or little region of space, they may be considered approximately linear. Therefore, by adding up all the contributions from the Jacobian determinants at each point in space, we can still calculate the change in the size of a region after transformation.\n",
    "\n",
    "In mathematics, __optimisation__ basically means the same thing, as much of the research is dedicated to finding the input values to functions, which correspond to either a maximum or a minimum of a system: global and local maxima as well as minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hessian\n",
    "For the Jacobian, we collected together all of the first order derivatives of a function into a vector. Now, we're going to collect all of the second order derivatives together into a matrix, which for a function of n variables, would look like this:\n",
    "\n",
    "With f(x,y,z) then \n",
    "$J = \n",
    "\\begin{vmatrix}\n",
    "\\frac{\\partial f}{\\partial x} & \\frac{\\partial f}{\\partial y} & \\frac{\\partial f}{\\partial z}\n",
    "\\end{vmatrix}$ and \n",
    "$H = \n",
    "\\begin{vmatrix}\n",
    "\\partial_{x,x}f & \\partial_{x,y}f & \\partial_{x,z}f \\\\\n",
    "\\partial_{y,x}f & \\partial_{y,y}f & \\partial_{y,z}f \\\\\n",
    "\\partial_{z,x}f & \\partial_{z,y}f & \\partial_{z,z}f \n",
    "\\end{vmatrix}\n",
    "$ \n",
    "\n",
    "It's easier to first calculate the Jacobian and then the Hessian. Hessian matrix is symmetrical along the diagonal.\n",
    "\n",
    "* Det(H) or |H| > 0 means then the point is either minimum or maximum.<br>\n",
    "* if the first term or upper left corner is positive then it is a minimum. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Chain Rule\n",
    "$f(x_1,x_2,x_3,...,x_n) = f(\\mathbf x)$ and each function of x also a function of t. <br>\n",
    "\n",
    "$\\frac{\\partial f}{\\partial \\mathbf x} = \n",
    "\\begin{vmatrix}\n",
    "\\frac{\\partial f}{\\partial x_1} \\\\\n",
    "\\frac{\\partial f}{\\partial x_2} \\\\\n",
    "\\frac{\\partial f}{\\partial x_3} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial f}{\\partial x_n}\n",
    "\\end{vmatrix} = (J_f)^T \\space\n",
    "$\n",
    "$\\frac{d \\mathbf x}{d t} = \n",
    "\\begin{vmatrix}\n",
    "\\frac{d x_1}{d t} \\\\\n",
    "\\frac{d x_2}{d t} \\\\\n",
    "\\frac{d x_3}{d t} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{d x_4}{d t}\n",
    "\\end{vmatrix} \\space\n",
    "$\n",
    "$\\frac{d f}{d t} = \\frac{\\partial f}{\\partial \\mathbf x} . \\frac{d \\mathbf x}{d t} = J_f \\frac{d \\mathbf x}{d t} $ <br> <br>\n",
    "$\\frac{d f}{d t} = \\frac{\\partial f}{\\partial \\mathbf x} \\frac{\\partial \\mathbf x}{\\partial \\mathbf u} \\frac{d \\mathbf x}{d t} = \n",
    "\\begin{vmatrix}\n",
    "\\frac{\\partial f}{\\partial x_1} & \\frac{\\partial f}{\\partial x_2}\n",
    "\\end{vmatrix} \n",
    "\\begin{vmatrix}\n",
    "\\frac{\\partial x_1}{\\partial u_1} & \\frac{\\partial x_1}{\\partial u_2} \\\\\n",
    "\\frac{\\partial x_2}{\\partial u_1} & \\frac{\\partial x_2}{\\partial u_2}\n",
    "\\end{vmatrix} \n",
    "\\begin{vmatrix}\n",
    "\\frac{d u_1}{d t} \\\\\n",
    "\\frac{d u_2}{d t}\n",
    "\\end{vmatrix}\n",
    "$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
